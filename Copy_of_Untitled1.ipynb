{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Untitled1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOaI2q6eP+QWgwnXMS70Cee",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AlexanderBelfort/MDPRKT/blob/main/Copy_of_Untitled1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "72edhWGtU8Ge"
      },
      "source": [
        "Since we will be working with a **docx** file, we must find a solution to convert **docx -> text** and then the text **bytes -> str** so we can use regular expressions on it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ugqI9d0VLgW"
      },
      "source": [
        "''' some possible sollutions '''\r\n",
        "\r\n",
        "%pip install python-docx\r\n",
        "%pip install textract\r\n",
        "%pip install docx2txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qDAK6e_1VQsE"
      },
      "source": [
        "Everytime we exit collab or run this notebook, we need to re-download the stopwords from nltk."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9SlpiaSVYhi"
      },
      "source": [
        "import nltk\r\n",
        "nltk.download('stopwords')\r\n",
        "from nltk.corpus import stopwords"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dgroh9C3VcYP"
      },
      "source": [
        "We will be doing string manipulation so we will need the string and regular expressions modules, and also file read/write operations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rbXrvASiVgzT"
      },
      "source": [
        "import string\r\n",
        "import re\r\n",
        "\r\n",
        "# load document into memory\r\n",
        "\r\n",
        "def load_doc(filename):\r\n",
        "\r\n",
        "  # open the file as read only\r\n",
        "  file = open(filename, 'r')\r\n",
        "\r\n",
        "  # read all text\r\n",
        "  text = file.read()\r\n",
        "\r\n",
        "  # close the file\r\n",
        "  file.close()\r\n",
        "  \r\n",
        "  return text"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GMOKQTRmWb6_"
      },
      "source": [
        "Tasks: \r\n",
        "\r\n",
        "All characters toLower().\r\n",
        "\r\n",
        "Split tokens on white space.\r\n",
        "\r\n",
        "Remove all punctuation from words.\r\n",
        "\r\n",
        "Remove all words that are not purely comprised of \r\n",
        "alphabetical characters.\r\n",
        "\r\n",
        "Remove all words that are known stop words.\r\n",
        "\r\n",
        "Remove all words that have a length â‰¤ 1 character."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SnrNnhsdWeUi"
      },
      "source": [
        "# turn a doc into clean tokens\r\n",
        "def clean_doc(doc):\r\n",
        "\r\n",
        "  # all text to lower chars\r\n",
        "  doc = doc.lower()\r\n",
        "  \r\n",
        "  # split into tokens by white space\r\n",
        "  tokens = doc.split()\r\n",
        "\r\n",
        "  # prepare regex for char filtering\r\n",
        "  # https://stackoverflow.com/questions/265960/best-way-to-strip-punctuation-from-a-string\r\n",
        "\r\n",
        "  re_punc = re.compile('[%s]' % re.escape(string.punctuation))\r\n",
        "\r\n",
        "\r\n",
        "  # remove punctuation from each word\r\n",
        "  tokens = [re_punc.sub('', w) for w in tokens]\r\n",
        "\r\n",
        "\r\n",
        "  # remove remaining tokens that are not alphabetic\r\n",
        "  tokens = [word for word in tokens if word.isalpha()]\r\n",
        "\r\n",
        "\r\n",
        "  # filter out stop words\r\n",
        "  stop_words = set(stopwords.words('english'))\r\n",
        "  tokens = [w for w in tokens if not w in stop_words]\r\n",
        "\r\n",
        "\r\n",
        "  # filter out short tokens\r\n",
        "  tokens = [word for word in tokens if len(word) > 1]\r\n",
        "\r\n",
        "\r\n",
        "  return tokens"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EgcSGLhpXgb2"
      },
      "source": [
        "Load the document for testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TWjbfH1_XjmJ",
        "outputId": "3efb89d4-ed22-4c7d-bd59-7d890e2f8904"
      },
      "source": [
        "# load the document\r\n",
        "filename = 'doc.txt'\r\n",
        "text = load_doc(filename)\r\n",
        "tokens = clean_doc(text)\r\n",
        "\r\n",
        "print('\\n\\n'.join(tokens))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "hello\n",
            "\n",
            "surgeon\n",
            "\n",
            "stefanov\n",
            "\n",
            "performing\n",
            "\n",
            "kidney\n",
            "\n",
            "surgery\n",
            "\n",
            "long\n",
            "\n",
            "operation\n",
            "\n",
            "sure\n",
            "\n",
            "want\n",
            "\n",
            "operation\n",
            "\n",
            "hospital\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}